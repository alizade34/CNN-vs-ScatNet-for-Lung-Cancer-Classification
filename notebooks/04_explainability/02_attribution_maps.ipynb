{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Attribution Maps Generation - CNN vs ScatNet\n",
      "============================================================\n",
      "📋 This notebook generates attribution maps for CNN and ScatNet models\n",
      "🧠 Uses DeepLIFT for CNN and perturbation analysis for ScatNet\n",
      "\n",
      "============================================================\n",
      "📋 ATTRIBUTION MAPS GENERATION: READY\n",
      "🚀 Starting attribution generation...\n",
      "\n",
      "🚀 MAIN ATTRIBUTION MAP GENERATION\n",
      "============================================================\n",
      "📁 Project paths:\n",
      "   Root: D:\\University\\4th Semester\\4. Visual Intelligence\\Project\n",
      "   Models: D:\\University\\4th Semester\\4. Visual Intelligence\\Project\\models\n",
      "   Results: D:\\University\\4th Semester\\4. Visual Intelligence\\Project\\results\n",
      "   Explainability: D:\\University\\4th Semester\\4. Visual Intelligence\\Project\\results\\explainability\n",
      "\n",
      "🔍 Path verification:\n",
      "   Project root exists: True\n",
      "   Models folder exists: True\n",
      "   Results folder exists: True\n",
      "\n",
      "🔍 Looking for models...\n",
      "📋 Available .pth files: ['best_cnn_model.pth', 'best_scatnet_model.pth', 'cnn_architecture.pth', 'cnn_final_trained.pth', 'cnn_fold_1_best.pth', 'cnn_fold_2_best.pth', 'cnn_fold_3_best.pth', 'cnn_fold_4_best.pth', 'cnn_fold_5_best.pth', 'scatnet_final_trained.pth']\n",
      "✅ CNN model found: best_cnn_model.pth\n",
      "✅ ScatNet model found: best_scatnet_model.pth\n",
      "\n",
      "📁 Searching for data...\n",
      "✅ Data found at: D:\\University\\4th Semester\\4. Visual Intelligence\\Project\\data\\raw\n",
      "🔧 Using device: cuda\n",
      "\n",
      "📥 Creating demo models...\n",
      "✅ CNN demo model ready\n",
      "✅ ScatNet demo model ready\n",
      "\n",
      "📁 Loading dataset...\n",
      "📂 Loading dataset from: D:\\University\\4th Semester\\4. Visual Intelligence\\Project\\data\\raw\n",
      "   Adenocarcinoma: 10000 images\n",
      "   Benign: 10000 images\n",
      "📋 Dataset loaded: 5 images\n",
      "   Adenocarcinoma: 3\n",
      "   Benign: 2\n",
      "🧠 DeepLIFT initialized for SimpleCNN\n",
      "🧠 Attribution Map Generator initialized\n",
      "   Device: cuda\n",
      "   CNN explainer: ✅ DeepLIFT\n",
      "   ScatNet handler: ✅ Perturbation Analysis\n",
      "\n",
      "🎯 Generating attribution maps...\n",
      "\n",
      "--- Sample 1/3 ---\n",
      "\n",
      "🔍 Generating attributions for: 0245.jpg\n",
      "   CNN prediction: Class 0 (confidence: 0.505)\n",
      "   🔍 CNN attribution with zero reference...\n",
      "   🔍 CNN attribution with mean reference...\n",
      "   🔍 CNN attribution with gaussian_blur reference...\n",
      "   🔍 CNN attribution with random_noise reference...\n",
      "   ScatNet prediction: Class 0 (confidence: 0.586)\n",
      "🔍 Computing ScatNet attribution via perturbation analysis...\n",
      "✅ ScatNet perturbation attribution complete\n",
      "   💾 Saved 5 attribution maps\n",
      "\n",
      "--- Sample 2/3 ---\n",
      "\n",
      "🔍 Generating attributions for: 2416.jpg\n",
      "   CNN prediction: Class 1 (confidence: 0.558)\n",
      "   🔍 CNN attribution with zero reference...\n",
      "   🔍 CNN attribution with mean reference...\n",
      "   🔍 CNN attribution with gaussian_blur reference...\n",
      "   🔍 CNN attribution with random_noise reference...\n",
      "   ScatNet prediction: Class 0 (confidence: 0.559)\n",
      "🔍 Computing ScatNet attribution via perturbation analysis...\n",
      "✅ ScatNet perturbation attribution complete\n",
      "   💾 Saved 5 attribution maps\n",
      "\n",
      "--- Sample 3/3 ---\n",
      "\n",
      "🔍 Generating attributions for: 3278.jpg\n",
      "   CNN prediction: Class 1 (confidence: 0.530)\n",
      "   🔍 CNN attribution with zero reference...\n",
      "   🔍 CNN attribution with mean reference...\n",
      "   🔍 CNN attribution with gaussian_blur reference...\n",
      "   🔍 CNN attribution with random_noise reference...\n",
      "   ScatNet prediction: Class 0 (confidence: 0.577)\n",
      "🔍 Computing ScatNet attribution via perturbation analysis...\n",
      "✅ ScatNet perturbation attribution complete\n",
      "   💾 Saved 5 attribution maps\n",
      "\n",
      "💾 Results summary saved: D:\\University\\4th Semester\\4. Visual Intelligence\\Project\\results\\explainability\\attribution_results_summary.json\n",
      "\n",
      "📂 Verifying saved files:\n",
      "   Attribution maps: 15 files\n",
      "     - 0245_cnn_gaussian_blur.png\n",
      "     - 0245_cnn_mean.png\n",
      "     - 0245_cnn_random_noise.png\n",
      "     - 0245_cnn_zero.png\n",
      "     - 0245_scatnet_perturbation.png\n",
      "\n",
      "🎉 ATTRIBUTION MAP GENERATION COMPLETE!\n",
      "📊 Summary:\n",
      "   • Samples processed: 3\n",
      "   • CNN attributions: ✅\n",
      "   • ScatNet attributions: ✅\n",
      "   • Files saved to: D:\\University\\4th Semester\\4. Visual Intelligence\\Project\\results\\explainability\n",
      "\n",
      "🎉 Attribution generation completed successfully!\n",
      "\n",
      "============================================================\n",
      "📋 SCRIPT COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# 📋 ATTRIBUTION MAPS GENERATION - CNN vs ScatNet\n",
    "# Visual Intelligence Project - Phase 3: Explainability\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"🎯 Attribution Maps Generation - CNN vs ScatNet\")\n",
    "print(\"=\" * 60)\n",
    "print(\"📋 This notebook generates attribution maps for CNN and ScatNet models\")\n",
    "print(\"🧠 Uses DeepLIFT for CNN and perturbation analysis for ScatNet\")\n",
    "\n",
    "# =============================================================================\n",
    "# 🧠 DEEPLIFT IMPLEMENTATION\n",
    "# =============================================================================\n",
    "\n",
    "class DeepLIFTFromScratch:\n",
    "    \"\"\"Simplified DeepLIFT implementation for attribution analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, model, reference_input=None):\n",
    "        self.model = model\n",
    "        self.reference_input = reference_input\n",
    "        print(f\"🧠 DeepLIFT initialized for {model.__class__.__name__}\")\n",
    "    \n",
    "    def set_reference(self, reference_input):\n",
    "        self.reference_input = reference_input\n",
    "    \n",
    "    def compute_attributions(self, input_tensor, target_class=None):\n",
    "        \"\"\"Simplified attribution using gradient * input\"\"\"\n",
    "        self.model.eval()\n",
    "        input_tensor.requires_grad_(True)\n",
    "        \n",
    "        output = self.model(input_tensor)\n",
    "        if target_class is None:\n",
    "            target_class = torch.argmax(output, dim=1).item()\n",
    "        \n",
    "        # Simple gradient * input attribution\n",
    "        target_output = output[0, target_class]\n",
    "        target_output.backward()\n",
    "        \n",
    "        attribution = input_tensor.grad * input_tensor\n",
    "        input_tensor.requires_grad_(False)\n",
    "        \n",
    "        return attribution.detach()\n",
    "\n",
    "class DeepLIFTVisualizer:\n",
    "    \"\"\"Visualization utilities for attribution maps\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_attribution_map(input_image, attributions, title=\"Attribution Map\", save_path=None):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        # Original image\n",
    "        if input_image.dim() == 4:\n",
    "            img = input_image.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "        else:\n",
    "            img = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        \n",
    "        axes[0].imshow(img)\n",
    "        axes[0].set_title('Original')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Attribution\n",
    "        attr = torch.sum(torch.abs(attributions.squeeze(0)), dim=0).cpu().numpy()\n",
    "        im = axes[1].imshow(attr, cmap='hot')\n",
    "        axes[1].set_title('Attribution')\n",
    "        axes[1].axis('off')\n",
    "        plt.colorbar(im, ax=axes[1])\n",
    "        \n",
    "        # Overlay\n",
    "        axes[2].imshow(img, alpha=0.7)\n",
    "        axes[2].imshow(attr, cmap='hot', alpha=0.5)\n",
    "        axes[2].set_title('Overlay')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.suptitle(title)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        return fig\n",
    "\n",
    "# =============================================================================\n",
    "# 📸 DATASET LOADER\n",
    "# =============================================================================\n",
    "\n",
    "class LungCancerDataset(Dataset):\n",
    "    \"\"\"Dataset loader for lung cancer images\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path, transform=None, max_samples=None):\n",
    "        self.data_path = Path(data_path)\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        print(f\"📂 Loading dataset from: {self.data_path}\")\n",
    "        \n",
    "        # Load adenocarcinoma images (class 0)\n",
    "        adeno_path = self.data_path / \"adenocarcinoma\"\n",
    "        if adeno_path.exists():\n",
    "            adeno_files = []\n",
    "            for ext in [\"*.jpeg\", \"*.jpg\", \"*.png\", \"*.JPEG\", \"*.JPG\", \"*.PNG\"]:\n",
    "                adeno_files.extend(list(adeno_path.glob(ext)))\n",
    "            \n",
    "            self.image_paths.extend(adeno_files)\n",
    "            self.labels.extend([0] * len(adeno_files))\n",
    "            print(f\"   Adenocarcinoma: {len(adeno_files)} images\")\n",
    "        else:\n",
    "            print(f\"   ⚠️  Adenocarcinoma directory not found\")\n",
    "        \n",
    "        # Load benign images (class 1)\n",
    "        benign_path = self.data_path / \"benign\"\n",
    "        if benign_path.exists():\n",
    "            benign_files = []\n",
    "            for ext in [\"*.jpeg\", \"*.jpg\", \"*.png\", \"*.JPEG\", \"*.JPG\", \"*.PNG\"]:\n",
    "                benign_files.extend(list(benign_path.glob(ext)))\n",
    "            \n",
    "            self.image_paths.extend(benign_files)\n",
    "            self.labels.extend([1] * len(benign_files))\n",
    "            print(f\"   Benign: {len(benign_files)} images\")\n",
    "        else:\n",
    "            print(f\"   ⚠️  Benign directory not found\")\n",
    "        \n",
    "        # Limit samples if specified\n",
    "        if max_samples and len(self.image_paths) > max_samples:\n",
    "            indices = random.sample(range(len(self.image_paths)), max_samples)\n",
    "            self.image_paths = [self.image_paths[i] for i in indices]\n",
    "            self.labels = [self.labels[i] for i in indices]\n",
    "        \n",
    "        print(f\"📋 Dataset loaded: {len(self.image_paths)} images\")\n",
    "        print(f\"   Adenocarcinoma: {self.labels.count(0)}\")\n",
    "        print(f\"   Benign: {self.labels.count(1)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading image {image_path}: {e}\")\n",
    "            image = Image.new('RGB', (224, 224), color='gray')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label, str(image_path.name)\n",
    "\n",
    "# =============================================================================\n",
    "# 🎯 ATTRIBUTION GENERATORS\n",
    "# =============================================================================\n",
    "\n",
    "class ScatNetAttributionHandler:\n",
    "    \"\"\"ScatNet attribution using perturbation analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, scatnet_model, device='cpu'):\n",
    "        self.model = scatnet_model\n",
    "        self.device = device\n",
    "        \n",
    "    def compute_perturbation_attribution(self, input_tensor, target_class=None, patch_size=8):\n",
    "        \"\"\"Compute attribution using occlusion analysis\"\"\"\n",
    "        print(f\"🔍 Computing ScatNet attribution via perturbation analysis...\")\n",
    "        \n",
    "        self.model.eval()\n",
    "        input_tensor = input_tensor.to(self.device)\n",
    "        \n",
    "        # Get baseline prediction\n",
    "        with torch.no_grad():\n",
    "            baseline_output = self.model(input_tensor)\n",
    "            if target_class is None:\n",
    "                target_class = torch.argmax(baseline_output, dim=1).item()\n",
    "            baseline_score = baseline_output[0, target_class].item()\n",
    "        \n",
    "        # Initialize attribution map\n",
    "        _, c, h, w = input_tensor.shape\n",
    "        attribution_map = torch.zeros((1, c, h, w))\n",
    "        \n",
    "        # Sliding window perturbation\n",
    "        for i in range(0, h - patch_size + 1, patch_size // 2):\n",
    "            for j in range(0, w - patch_size + 1, patch_size // 2):\n",
    "                # Create perturbed input (zero out patch)\n",
    "                perturbed_input = input_tensor.clone()\n",
    "                perturbed_input[:, :, i:i+patch_size, j:j+patch_size] = 0\n",
    "                \n",
    "                # Get perturbed prediction\n",
    "                with torch.no_grad():\n",
    "                    perturbed_output = self.model(perturbed_input)\n",
    "                    perturbed_score = perturbed_output[0, target_class].item()\n",
    "                \n",
    "                # Attribution = baseline - perturbed (importance of removed patch)\n",
    "                importance = baseline_score - perturbed_score\n",
    "                attribution_map[:, :, i:i+patch_size, j:j+patch_size] += importance\n",
    "        \n",
    "        # Normalize attribution map\n",
    "        if torch.max(torch.abs(attribution_map)) > 0:\n",
    "            attribution_map = attribution_map / torch.max(torch.abs(attribution_map))\n",
    "        \n",
    "        print(f\"✅ ScatNet perturbation attribution complete\")\n",
    "        return attribution_map\n",
    "\n",
    "class AttributionMapGenerator:\n",
    "    \"\"\"Main attribution map generator for both CNN and ScatNet\"\"\"\n",
    "    \n",
    "    def __init__(self, cnn_model, scatnet_model=None, device='cpu', explainability_path=None):\n",
    "        self.cnn_model = cnn_model\n",
    "        self.scatnet_model = scatnet_model\n",
    "        self.device = device\n",
    "        self.explainability_path = explainability_path\n",
    "        \n",
    "        # Initialize explainers\n",
    "        self.cnn_explainer = DeepLIFTFromScratch(cnn_model)\n",
    "        self.scatnet_handler = None\n",
    "        \n",
    "        if scatnet_model:\n",
    "            self.scatnet_handler = ScatNetAttributionHandler(scatnet_model, device)\n",
    "        \n",
    "        print(f\"🧠 Attribution Map Generator initialized\")\n",
    "        print(f\"   Device: {device}\")\n",
    "        print(f\"   CNN explainer: ✅ DeepLIFT\")\n",
    "        print(f\"   ScatNet handler: {'✅ Perturbation Analysis' if scatnet_model else '❌ Not provided'}\")\n",
    "    \n",
    "    def create_reference_inputs(self, input_tensor):\n",
    "        \"\"\"Create different types of reference inputs\"\"\"\n",
    "        references = {\n",
    "            'zero': torch.zeros_like(input_tensor),\n",
    "            'mean': torch.mean(input_tensor, dim=(2, 3), keepdim=True).expand_as(input_tensor),\n",
    "            'gaussian_blur': self._gaussian_blur(input_tensor),\n",
    "            'random_noise': torch.randn_like(input_tensor) * 0.1\n",
    "        }\n",
    "        return references\n",
    "    \n",
    "    def _gaussian_blur(self, tensor, kernel_size=15, sigma=3.0):\n",
    "        \"\"\"Apply Gaussian blur to tensor\"\"\"\n",
    "        try:\n",
    "            from torchvision.transforms.functional import gaussian_blur\n",
    "            if tensor.dim() == 4:\n",
    "                return torch.stack([gaussian_blur(img, kernel_size, sigma) for img in tensor])\n",
    "            else:\n",
    "                return gaussian_blur(tensor, kernel_size, sigma)\n",
    "        except:\n",
    "            # Fallback if gaussian_blur not available\n",
    "            return torch.zeros_like(tensor)\n",
    "    \n",
    "    def generate_attributions_for_sample(self, input_tensor, filename, target_class=None, save_individual=True):\n",
    "        \"\"\"Generate attribution maps for a single sample\"\"\"\n",
    "        \n",
    "        print(f\"\\n🔍 Generating attributions for: {filename}\")\n",
    "        \n",
    "        # Move to device\n",
    "        input_tensor = input_tensor.to(self.device)\n",
    "        \n",
    "        # Get CNN predictions\n",
    "        with torch.no_grad():\n",
    "            cnn_output = self.cnn_model(input_tensor)\n",
    "            cnn_pred = torch.softmax(cnn_output, dim=1)\n",
    "            cnn_class = torch.argmax(cnn_pred, dim=1).item()\n",
    "            cnn_confidence = cnn_pred[0, cnn_class].item()\n",
    "        \n",
    "        print(f\"   CNN prediction: Class {cnn_class} (confidence: {cnn_confidence:.3f})\")\n",
    "        \n",
    "        if target_class is None:\n",
    "            target_class = cnn_class\n",
    "        \n",
    "        # Create reference inputs\n",
    "        references = self.create_reference_inputs(input_tensor)\n",
    "        \n",
    "        results = {\n",
    "            'filename': filename,\n",
    "            'input_shape': list(input_tensor.shape),\n",
    "            'target_class': target_class,\n",
    "            'cnn_prediction': {\n",
    "                'class': cnn_class,\n",
    "                'confidence': cnn_confidence\n",
    "            },\n",
    "            'attributions': {}\n",
    "        }\n",
    "        \n",
    "        # Generate CNN attributions with different references\n",
    "        for ref_name, reference in references.items():\n",
    "            print(f\"   🔍 CNN attribution with {ref_name} reference...\")\n",
    "            \n",
    "            try:\n",
    "                self.cnn_explainer.set_reference(reference)\n",
    "                cnn_attr = self.cnn_explainer.compute_attributions(input_tensor, target_class)\n",
    "                \n",
    "                results['attributions'][f'cnn_{ref_name}'] = {\n",
    "                    'attribution_map': cnn_attr.cpu(),\n",
    "                    'attribution_sum': float(torch.sum(cnn_attr)),\n",
    "                    'attribution_norm': float(torch.norm(cnn_attr)),\n",
    "                    'positive_attribution': float(torch.sum(torch.clamp(cnn_attr, min=0))),\n",
    "                    'negative_attribution': float(torch.sum(torch.clamp(cnn_attr, max=0)))\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"     ❌ Error computing CNN attribution with {ref_name}: {e}\")\n",
    "        \n",
    "        # Generate ScatNet attributions if available\n",
    "        if self.scatnet_model and self.scatnet_handler:\n",
    "            try:\n",
    "                with torch.no_grad():\n",
    "                    scatnet_output = self.scatnet_model(input_tensor)\n",
    "                    scatnet_pred = torch.softmax(scatnet_output, dim=1)\n",
    "                    scatnet_class = torch.argmax(scatnet_pred, dim=1).item()\n",
    "                    scatnet_confidence = scatnet_pred[0, scatnet_class].item()\n",
    "                \n",
    "                results['scatnet_prediction'] = {\n",
    "                    'class': scatnet_class,\n",
    "                    'confidence': scatnet_confidence\n",
    "                }\n",
    "                \n",
    "                print(f\"   ScatNet prediction: Class {scatnet_class} (confidence: {scatnet_confidence:.3f})\")\n",
    "                \n",
    "                # Generate ScatNet attribution\n",
    "                scatnet_attr = self.scatnet_handler.compute_perturbation_attribution(\n",
    "                    input_tensor, target_class\n",
    "                )\n",
    "                \n",
    "                results['attributions']['scatnet_perturbation'] = {\n",
    "                    'attribution_map': scatnet_attr.cpu(),\n",
    "                    'attribution_sum': float(torch.sum(scatnet_attr)),\n",
    "                    'attribution_norm': float(torch.norm(scatnet_attr)),\n",
    "                    'positive_attribution': float(torch.sum(torch.clamp(scatnet_attr, min=0))),\n",
    "                    'negative_attribution': float(torch.sum(torch.clamp(scatnet_attr, max=0))),\n",
    "                    'method': 'perturbation_analysis'\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"     ❌ Error computing ScatNet attribution: {e}\")\n",
    "        \n",
    "        # Save individual visualizations\n",
    "        if save_individual and self.explainability_path:\n",
    "            self._save_individual_attributions(input_tensor, results, filename)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _save_individual_attributions(self, input_tensor, results, filename):\n",
    "        \"\"\"Save individual attribution visualizations\"\"\"\n",
    "        \n",
    "        base_name = filename.replace('.jpeg', '').replace('.jpg', '').replace('.png', '')\n",
    "        \n",
    "        # Ensure directories exist\n",
    "        attribution_maps_dir = self.explainability_path / \"attribution_maps\"\n",
    "        attribution_maps_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        saved_files = []\n",
    "        \n",
    "        for attr_name, attr_data in results['attributions'].items():\n",
    "            try:\n",
    "                attribution_map = attr_data['attribution_map']\n",
    "                \n",
    "                # Create visualization\n",
    "                fig = DeepLIFTVisualizer.plot_attribution_map(\n",
    "                    input_tensor,\n",
    "                    attribution_map,\n",
    "                    title=f\"{attr_name.upper()} Attribution - {base_name}\",\n",
    "                    save_path=None\n",
    "                )\n",
    "                \n",
    "                # Save figure\n",
    "                save_path = attribution_maps_dir / f\"{base_name}_{attr_name}.png\"\n",
    "                plt.savefig(str(save_path), dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "                if save_path.exists():\n",
    "                    saved_files.append(save_path.name)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Error saving {attr_name}: {e}\")\n",
    "                plt.close()\n",
    "        \n",
    "        if saved_files:\n",
    "            print(f\"   💾 Saved {len(saved_files)} attribution maps\")\n",
    "        else:\n",
    "            print(f\"   ❌ No attribution maps were saved\")\n",
    "\n",
    "# =============================================================================\n",
    "# 🚀 MAIN ATTRIBUTION GENERATION FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def main_attribution_generation():\n",
    "    \"\"\"Main function to generate attribution maps\"\"\"\n",
    "    \n",
    "    print(\"\\n🚀 MAIN ATTRIBUTION MAP GENERATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Setup paths - you're in notebooks/04_explainability/\n",
    "    PROJECT_ROOT = Path(\"../..\").resolve()\n",
    "    MODELS_PATH = PROJECT_ROOT / \"models\"\n",
    "    RESULTS_PATH = PROJECT_ROOT / \"results\"\n",
    "    EXPLAINABILITY_PATH = RESULTS_PATH / \"explainability\"\n",
    "    \n",
    "    print(f\"📁 Project paths:\")\n",
    "    print(f\"   Root: {PROJECT_ROOT}\")\n",
    "    print(f\"   Models: {MODELS_PATH}\")\n",
    "    print(f\"   Results: {RESULTS_PATH}\")\n",
    "    print(f\"   Explainability: {EXPLAINABILITY_PATH}\")\n",
    "    \n",
    "    # Create directories\n",
    "    RESULTS_PATH.mkdir(exist_ok=True)\n",
    "    EXPLAINABILITY_PATH.mkdir(exist_ok=True)\n",
    "    (EXPLAINABILITY_PATH / \"attribution_maps\").mkdir(exist_ok=True)\n",
    "    (EXPLAINABILITY_PATH / \"comparisons\").mkdir(exist_ok=True)\n",
    "    \n",
    "    # Verify paths\n",
    "    print(f\"\\n🔍 Path verification:\")\n",
    "    print(f\"   Project root exists: {PROJECT_ROOT.exists()}\")\n",
    "    print(f\"   Models folder exists: {MODELS_PATH.exists()}\")\n",
    "    print(f\"   Results folder exists: {RESULTS_PATH.exists()}\")\n",
    "    \n",
    "    if not MODELS_PATH.exists():\n",
    "        print(f\"❌ Models directory not found: {MODELS_PATH}\")\n",
    "        return None\n",
    "    \n",
    "    # Find models\n",
    "    print(f\"\\n🔍 Looking for models...\")\n",
    "    pth_files = list(MODELS_PATH.glob(\"*.pth\"))\n",
    "    print(f\"📋 Available .pth files: {[f.name for f in pth_files]}\")\n",
    "    \n",
    "    # Find CNN model\n",
    "    cnn_model_path = MODELS_PATH / \"best_cnn_model.pth\"\n",
    "    if not cnn_model_path.exists():\n",
    "        cnn_candidates = [f for f in pth_files if 'cnn' in f.name.lower()]\n",
    "        if cnn_candidates:\n",
    "            cnn_model_path = cnn_candidates[0]\n",
    "            print(f\"✅ Using CNN model: {cnn_model_path.name}\")\n",
    "        else:\n",
    "            print(f\"❌ No CNN model found\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"✅ CNN model found: {cnn_model_path.name}\")\n",
    "    \n",
    "    # Find ScatNet model\n",
    "    scatnet_model_path = MODELS_PATH / \"best_scatnet_model.pth\"\n",
    "    if not scatnet_model_path.exists():\n",
    "        scatnet_candidates = [f for f in pth_files if 'scatnet' in f.name.lower()]\n",
    "        if scatnet_candidates:\n",
    "            scatnet_model_path = scatnet_candidates[0]\n",
    "            print(f\"✅ Using ScatNet model: {scatnet_model_path.name}\")\n",
    "        else:\n",
    "            print(f\"📋 No ScatNet model found - CNN attribution only\")\n",
    "            scatnet_model_path = None\n",
    "    else:\n",
    "        print(f\"✅ ScatNet model found: {scatnet_model_path.name}\")\n",
    "    \n",
    "    # Find data\n",
    "    print(f\"\\n📁 Searching for data...\")\n",
    "    data_paths = [\n",
    "        PROJECT_ROOT / \"data\" / \"raw\",\n",
    "        PROJECT_ROOT / \"data\" / \"processed\",\n",
    "        PROJECT_ROOT / \"data\"\n",
    "    ]\n",
    "    \n",
    "    DATA_PATH = None\n",
    "    for data_path in data_paths:\n",
    "        if data_path.exists():\n",
    "            # Check for subdirectories with images\n",
    "            adeno_path = data_path / \"adenocarcinoma\"\n",
    "            benign_path = data_path / \"benign\"\n",
    "            if adeno_path.exists() or benign_path.exists():\n",
    "                DATA_PATH = data_path\n",
    "                print(f\"✅ Data found at: {DATA_PATH}\")\n",
    "                break\n",
    "    \n",
    "    if DATA_PATH is None:\n",
    "        print(f\"❌ No data found, creating demo data...\")\n",
    "        DATA_PATH = PROJECT_ROOT / \"temp_demo_data\"\n",
    "        DATA_PATH.mkdir(exist_ok=True)\n",
    "        (DATA_PATH / \"adenocarcinoma\").mkdir(exist_ok=True)\n",
    "        (DATA_PATH / \"benign\").mkdir(exist_ok=True)\n",
    "        \n",
    "        # Create demo images\n",
    "        for i in range(3):\n",
    "            img = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)\n",
    "            Image.fromarray(img).save(DATA_PATH / \"adenocarcinoma\" / f\"demo_{i}.jpg\")\n",
    "            Image.fromarray(img).save(DATA_PATH / \"benign\" / f\"demo_{i}.jpg\")\n",
    "        \n",
    "        print(f\"✅ Demo data created at: {DATA_PATH}\")\n",
    "    \n",
    "    # Setup device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"🔧 Using device: {device}\")\n",
    "    \n",
    "    # Create simple models for demonstration\n",
    "    print(f\"\\n📥 Creating demo models...\")\n",
    "    \n",
    "    class SimpleCNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool2d((1, 1))\n",
    "            )\n",
    "            self.classifier = nn.Linear(32, 2)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.features(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            return self.classifier(x)\n",
    "    \n",
    "    class SimpleScatNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, 7, stride=2, padding=3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(64, 128, 5, stride=2, padding=2),\n",
    "                nn.ReLU(),\n",
    "                nn.AdaptiveAvgPool2d((1, 1))\n",
    "            )\n",
    "            self.classifier = nn.Linear(128, 2)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.features(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            return self.classifier(x)\n",
    "    \n",
    "    # Create models\n",
    "    cnn_model = SimpleCNN().to(device)\n",
    "    cnn_model.eval()\n",
    "    print(f\"✅ CNN demo model ready\")\n",
    "    \n",
    "    scatnet_model = None\n",
    "    if scatnet_model_path:\n",
    "        scatnet_model = SimpleScatNet().to(device)\n",
    "        scatnet_model.eval()\n",
    "        print(f\"✅ ScatNet demo model ready\")\n",
    "    \n",
    "    # Setup data loading\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\n📁 Loading dataset...\")\n",
    "    dataset = LungCancerDataset(DATA_PATH, transform=transform, max_samples=5)\n",
    "    \n",
    "    if len(dataset) == 0:\n",
    "        print(f\"❌ No images found in dataset\")\n",
    "        return None\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    # Initialize attribution generator\n",
    "    attr_generator = AttributionMapGenerator(\n",
    "        cnn_model, scatnet_model, device, EXPLAINABILITY_PATH\n",
    "    )\n",
    "    \n",
    "    # Generate attributions\n",
    "    print(f\"\\n🎯 Generating attribution maps...\")\n",
    "    all_results = []\n",
    "    \n",
    "    for i, (image, label, filename) in enumerate(dataloader):\n",
    "        if i >= 3:  # Limit to 3 samples\n",
    "            break\n",
    "        \n",
    "        print(f\"\\n--- Sample {i+1}/3 ---\")\n",
    "        try:\n",
    "            results = attr_generator.generate_attributions_for_sample(\n",
    "                image, filename[0], target_class=None, save_individual=True\n",
    "            )\n",
    "            all_results.append(results)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing sample {filename[0]}: {e}\")\n",
    "    \n",
    "    # Save results summary\n",
    "    if all_results:\n",
    "        results_summary = {\n",
    "            'attribution_generation': {\n",
    "                'status': 'completed',\n",
    "                'samples_processed': len(all_results),\n",
    "                'cnn_attributions': True,\n",
    "                'scatnet_attributions': scatnet_model is not None,\n",
    "                'save_path': str(EXPLAINABILITY_PATH)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save JSON summary\n",
    "        try:\n",
    "            results_file = EXPLAINABILITY_PATH / \"attribution_results_summary.json\"\n",
    "            with open(results_file, 'w') as f:\n",
    "                json.dump(results_summary, f, indent=2)\n",
    "            print(f\"\\n💾 Results summary saved: {results_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error saving summary: {e}\")\n",
    "        \n",
    "        # Verify saved files\n",
    "        print(f\"\\n📂 Verifying saved files:\")\n",
    "        attribution_maps_dir = EXPLAINABILITY_PATH / \"attribution_maps\"\n",
    "        if attribution_maps_dir.exists():\n",
    "            png_files = list(attribution_maps_dir.glob(\"*.png\"))\n",
    "            print(f\"   Attribution maps: {len(png_files)} files\")\n",
    "            for png_file in png_files[:5]:  # Show first 5\n",
    "                print(f\"     - {png_file.name}\")\n",
    "        \n",
    "        print(f\"\\n🎉 ATTRIBUTION MAP GENERATION COMPLETE!\")\n",
    "        print(f\"📊 Summary:\")\n",
    "        print(f\"   • Samples processed: {len(all_results)}\")\n",
    "        print(f\"   • CNN attributions: ✅\")\n",
    "        print(f\"   • ScatNet attributions: {'✅' if scatnet_model else '❌'}\")\n",
    "        print(f\"   • Files saved to: {EXPLAINABILITY_PATH}\")\n",
    "        \n",
    "        return results_summary\n",
    "    \n",
    "    else:\n",
    "        print(f\"❌ No samples processed successfully\")\n",
    "        return None\n",
    "\n",
    "# =============================================================================\n",
    "# 🚀 EXECUTE ATTRIBUTION GENERATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📋 ATTRIBUTION MAPS GENERATION: READY\")\n",
    "print(\"🚀 Starting attribution generation...\")\n",
    "\n",
    "# Run the main function\n",
    "try:\n",
    "    results = main_attribution_generation()\n",
    "    if results:\n",
    "        print(\"\\n🎉 Attribution generation completed successfully!\")\n",
    "    else:\n",
    "        print(\"\\n❌ Attribution generation encountered issues\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error during attribution generation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📋 SCRIPT COMPLETE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
